# Pool of credentials to use to crawl (each pool is specified by four properties ending with the same number: integer from 1 to 150)
# Credentials of the pool are used in a round robin way.
#    - for streaming crawlers it is needed to specify only one pool of credentials
#    - for rest crawler, more credential pools are specified, faster is the crawling process
# IMPORTANT: it is possible to specify up to 150 credentials
consumerKey_1=PUT_YOUR_CONSUMER_KEY_NUM_1
consumerSecret_1=PUT_YOUR_CONSUMER_SECRET_NUM_1
token_1=PUT_YOUR_TOKEN_NUM_1
tokenSecret_1=PUT_YOUR_TOKEN_SECRET_NUM_1


consumerKey_2=PUT_YOUR_CONSUMER_KEY_NUM_2
consumerSecret_2=PUT_YOUR_CONSUMER_SECRET_NUM_2
token_2=PUT_YOUR_TOKEN_NUM_2
tokenSecret_2=PUT_YOUR_TOKEN_SECRET_NUM_2


####################################################################################
# REST Cralwer of Twitter - by list of tweet IDs (tweetID)
# Class: org.backingdata.twitter.crawler.rest.TwitterRESTTweetIDlistCrawler
#   - Full path of the txt file to read tweet IDs from (one tweet ID per line)
tweetID.fullPathTweetIDs=
#   - Full path of the output folder to store crawling results 
tweetID.fullOutputDirPath=
#   - Storage format: "json" to store one tweet per line as tweet JSON object or "tab" to store one tweet per line as TWEET_ID<TAB>TWEET_TEXT
tweetID.outputFormat=json


####################################################################################
# REST Cralwer of Twitter - by keyword(s)
# Class: org.backingdata.twitter.crawler.rest.TwitterRESTKeywordSearchCrawler
#   - Full path of the txt file to read terms from (one term ID per line)
tweetKeyword.fullPathKeywordList=
#   - Full path of the output folder to store crawling results 
tweetKeyword.fullOutputDirPath=
#   - Storage format: "json" to store one tweet per line as tweet JSON object or "tab" to store one tweet per line as TWEET_ID<TAB>TWEET_TEXT
tweetID.outputFormat=json
#   - If not empty, it is possible specify a language to retrieve only tweet of a specific language (en, es, it, etc.) - if empty all tweet are retrieved, indipendently from their language
#    IMPORTANT: The language code may be formatted as ISO 639-1 alpha-2 (en), ISO 639-3 alpha-3 (msa), or ISO 639-1 alpha-2 combined with an ISO 3166-1 alpha-2 localization (zh-tw).
tweetID.languageFilter=


####################################################################################
# REST Cralwer of Twitter - by account timeline
# HOWTO: a new file with all the most recent tweets of the timelines of the users specified is created
# Class: org.backingdata.twitter.crawler.rest.TwitterRESTAccountTimelineCrawler
#   - Full path of the txt file to read account IDs from (line format: ACCOUNT NAME <TAB> ACCOUNT_ID_LONG)
#   Example: 
#   bbc	612473
#   arxiv	808633423300624384
tweetTimeline.fullPathAccountIDs=
#   - Full path of the output folder to store crawling results 
tweetTimeline.fullOutputDirPath=
#   - Storage format: "json" to store one tweet per line as tweet JSON object or "tab" to store one tweet per line as TWEET_ID<TAB>TWEET_TEXT
tweetTimeline.outputFormat=json


####################################################################################
# TREAMING Cralwer of Twitter - retrieves all tweets matching some specific keywords / users and/or in some specific language.
# Class: org.backingdata.twitter.crawler.streaming.TwitterSTREAMHashtagCrawler
#   - Full path of the txt file to read terms from (one term ID per line)
tweetSTREAMkeyword.fullPathKeywordList=
#   - Full path of the txt file to read terms from (line format: ACCOUNT NAME <TAB> ACCOUNT_ID_LONG)
#   Example: 
#   bbc	662708106
#   arxiv	1149879325
tweetSTREAMkeyword.fullPathUserList=
#   - Full path of the output folder to store crawling results 
tweetSTREAMkeyword.fullOutputDirPath=
#   - Storage format: "json" to store one tweet per line as tweet JSON object or "tab" to store one tweet per line as TWEET_ID<TAB>TWEET_TEXT
tweetSTREAMkeyword.outputFormat=json
#   - If not empty, it is possible specify a comma separated language list to retrieve only tweet of a specific language (en, es, it, etc.) - if empty all tweet are retrieved, indipendently from their language
#    IMPORTANT: The language code may be formatted as ISO 639-1 alpha-2 (en), ISO 639-3 alpha-3 (msa), or ISO 639-1 alpha-2 combined with an ISO 3166-1 alpha-2 localization (zh-tw).
tweetSTREAMkeyword.languageFilter=
#   - If not empty, it is possible specify a number of seconds - max number of tweet to store per seconds per user or keyword 
tweetSTREAMkeyword.limitByOneTweetPerXsec=


####################################################################################
# STREAMING Cralwer of Twitter - retrieves all tweets generated inside a bounding box from a list and/or in some specific language.
# Class: org.backingdata.twitter.crawler.streaming.TwitterSTREAMBboxCrawler
#   - Full path of the txt file to read bounding boxes from (one bounding box per line - line format: BOUNDING BOX NAME <TAB> BOUNDING BOX COORDINATES)
#   BOUNDING BOX COORDINATES should be always a comma-separated list of doubles in the following order: lngSW, latSW, lngNE, latNE
#   Example: 
#   BBOX_NAME1	2.1390724182128906,41.363024324309784,2.1680831909179688,41.40565583808169
#   BBAX_NAME2	2.06268310546875,41.3532318743157,2.1028518676757812,41.37732380781499
tweetSTREAMbbox.fullPathBoundingBoxes=
#   - Full path of the output folder to store crawling results 
tweetSTREAMbbox.fullOutputDirPath=
#   - Storage format: "json" to store one tweet per line as tweet JSON object or "tab" to store one tweet per line as TWEET_ID<TAB>TWEET_TEXT
tweetSTREAMbbox.outputFormat=json
#   - If not empty, it is possible specify a comma separated language list to retrieve only tweet of a specific language (en, es, it, etc.) - if empty all tweet are retrieved, indipendently from their language
#    IMPORTANT: The language code may be formatted as ISO 639-1 alpha-2 (en), ISO 639-3 alpha-3 (msa), or ISO 639-1 alpha-2 combined with an ISO 3166-1 alpha-2 localization (zh-tw).
tweetSTREAMbbox.languageFilter=

